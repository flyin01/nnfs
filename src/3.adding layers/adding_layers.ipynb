{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding Layers**  \n",
    "So far we have just had one layer, which is effectively and output layer. We have currently no hidden layer. A hidden layer is not an input or output layer, we see data as they are handed to the input player and the resulting data from the output layer. Layers between these two endpoints have values that we dont necesseraly handle that is why they are called \"hidded\". We will explore why we want hidden layers later on. For now, we will assume the two layers we want will be hidden layers and we have not yet created an output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before adding another layer, let´s think of what we start with. The first layer will have an input with 4 features into a hidden layer with 3 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we wish to add another layer, by doing so we must make sure that the expected input to the new layer mathes the previous layer´s output. We have set the number of neurons in a layer by setting how many weight sets and biases we have. The previous layer has 3 weight sets and 3 biases so we know it has 3 neurons. For the next layer we can have as many weight sets as we want (how many neurons this new layer will have) but each of those weight sets must hae 3 discrete weights. To create this new layer we copy pase our weights and biases to version 2 of these and add the values to new made up sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "           [-0.5, 0.12, -0.33],\n",
    "           [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1.0, 2.0, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can do np.dot() on plain Python list of lists as numpy will convert the to matrices internally. We only convert the weights ourselves to perform the transposition first .T since plain Pyhon list of lists does not support this. Biases we do not need to make into np array since numpy will do that internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our nerual network could be respresented as:\n",
    "* 4 feature inputs\n",
    "* hidden layers of 3 neurons each"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
