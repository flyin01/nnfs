{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a **Dense Layer Class**, we will begin with two methods. This is also called sometimes fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    \n",
    "    # layer of initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # initialize weights and biases\n",
    "        pass # using pass statement as placeholder\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # calculate output values from inputs, weights and biases\n",
    "        pass # using pass statement as placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights are often initialized on random for a model, but this is not always the case, you can have something else than random like a pre-trained model. But we will for  now use random initialization.  \n",
    "  \n",
    "Next we have forward method. When we pass data through a model from start to end this is called forward pass. You can also have data loop back. But we will perform a regular forward pass.  \n",
    "  \n",
    "Adding to the Layer_Dense class code we will add the random initialization of weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer initialization\n",
    "def __init__(self, n_inputs, n_neurons):\n",
    "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "    self.biases = np.zeros((1, n_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are setting weights to be random and biases to be 0. We are initializing weights to be (inputs, neurons) rather than (neurons, inputs). We do this ahead instead of transposing every time we perform a forward pass. The reason for 0 biases, this is the most common initialization for biases. Sometime you want to try something else, like when you have dead neurons. This is related to activation functions. It is possible for weights * inputs + biases not to meet the threshold of the step function, it means that the neuron outputs a 0. This is not as such a big issue. But with inreasing number of neurons outputting 0 this will lead to that the network is in its essence non-trainable or called \"dead\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.random.randn` and the `np.zeros` are methods to initialize arrays. The `np.random.randn` will generate normally distributed with mean 0 and sigma 0 random numbers. In general, neural networks work best with values between -1 and +1 which we will see eventually. We will multipy this normal distribution for weights with the scalar 0.01 to get numbers a few magnitudes smaller. This is because otherwise the model will take longer time to fit the data during training process and starting value will be disproportionally larger compared to updates being made during training. The idea is to start the model with small non-zero values that wont affect the training. We can experiment using other values of the scalar.  \n",
    "  \n",
    "The `np.random.rand` takes dimension sizes as parameters and creates the output array with this shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
      " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]]\n"
     ]
    }
   ],
   "source": [
    "nnfs.init()\n",
    "\n",
    "print(np.random.rand(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79172504 0.52889492 0.56804456 0.92559664 0.07103606]\n",
      " [0.0871293  0.0202184  0.83261985 0.77815675 0.87001215]]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.rand(2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print out is a 2x5 array which is an array of shape of (2,5).  \n",
    "  \n",
    "The `np.zeros()` takes a array shape as argument and returns an array of the shape filled with 0Â´s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((2,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this to initialize the biases with shape (1, n_neurons) as a row_vector so we can add it to the dot product later without need of transposing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01764052  0.00400157  0.00978738  0.02240893]\n",
      " [ 0.01867558 -0.00977278  0.00950088 -0.00151357]]\n",
      "[[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Example of how to initialize weight and biases\n",
    "import numpy as np\n",
    "import nnfs\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "n_inputs = 2\n",
    "n_neurons = 4\n",
    "\n",
    "weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "biases = np.zeros((1, n_neurons))\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets run all the code at once!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.97437393e-05 3.68895635e-05 8.37819971e-05]\n",
      " [1.46999708e-04 9.15808050e-05 1.40212578e-04]\n",
      " [2.07372344e-04 1.30936343e-04 5.65641167e-05]\n",
      " [2.86790368e-04 1.80765084e-04 1.03854705e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Full layer_Dense class so far:\n",
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class Layer_Dense:\n",
    "    \n",
    "    # layer of initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.rand(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "# Generate some data to use the new class instead of our hardcoded calculations\n",
    "# to perform a forward pass\n",
    "\n",
    "# dataset creation\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# create Dense Layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# check the output of the first few samples\n",
    "print(dense1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is 5 rows of data that have 3 values each. Each of the 3 values is the values from the 3 neurons in the dense1 layer after passing in each of the samples. We have a neural network model that is still missing the activation function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
